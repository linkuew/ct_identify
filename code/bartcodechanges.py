# -*- coding: utf-8 -*-
"""bartCodeChanges.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ieGGI31YeTcfvQhylBpm8fjLjjoJ3gwQ
"""

import argparse
import subprocess
import os
import json
import getopt, sys
import numpy as np
import pandas as pd
from datasets import Dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from transformers import DataCollatorWithPadding
from transformers import TrainingArguments, Trainer
from transformers import BartForSequenceClassification, BartTokenizer
from datasets import load_metric
import time
import torch

# load model
model_name = "facebook/bart-base"
tokenizer = BartTokenizer.from_pretrained(model_name)
model = BartForSequenceClassification.from_pretrained(model_name, num_labels=2)

def preprocess_function(dataset):
    tokenized_text = tokenizer(dataset['text'], padding="max_length", max_length=1025, truncation=True, return_tensors="pt")

    if tokenized_text['input_ids'].size(1) <= 1024:
        # If the length is less than or equal to 1024, no need for further processing
        return tokenized_text

    # If the length is greater than 1024, truncate the input
    truncated_input_ids = tokenized_text['input_ids'][:, :1024]
    truncated_attention_mask = tokenized_text['attention_mask'][:, :1024]

    tokenized_text['input_ids'] = torch.LongTensor(truncated_input_ids)
    tokenized_text['attention_mask'] = torch.LongTensor(truncated_attention_mask)

    return tokenized_text

def compute_metrics(eval_pred):
    load_f1 = load_metric("f1")
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)

    f1 = load_f1.compute(predictions=predictions, references=labels, average = 'macro')["f1"]

    return {"f1": f1}

#Copied over functions from library to troubleshoot in Google colab
# glob_dict = {'bf' : 0, 'fe' : 1, 'cc' : 2, 'va' : 3, 'pg' : 4}

# if we use the fixed data and read them from seed, please comment out the following line
glob_dict = {'bf' : 'big.foot', 'fe' : 'flat.earth', 'cc' : 'climate', 'va' : 'vaccine', 'pg' : 'pizzagate'}
glob_dict_rev = {value:key for key, value in glob_dict.items()}
ct_lsts = list(glob_dict.keys())
#
# Read data from conspiracy seed
##
def read_data(seed,eval):
    tr = pd.read_csv('../data/train_'+seed+'.csv')
    val = pd.read_csv('../data/val_'+seed+'.csv')
    te = pd.read_csv('../data/test_'+eval+'.csv')

    return tr, te, val

def read_data_merge(seed,eval):
    tr = pd.read_csv('../data/data_4/train_'+seed+'.csv')
    val = pd.read_csv('../data/data_4/val_'+seed+'.csv')
    te = pd.read_csv('../data/test_'+eval+'.csv')

    return tr, te, val


##
# Prints out the usage statements
##
def usage(script_name):
    print("Usage: python " + script_name + " -d [bf|fe|cl|va|pg] -e [bf|fe|cl|va|pg] -m [merge] -f [char|word] -r i,j", end="")
    if script_name[0] == 'f':
        print('-k [num_features]')
        print('-s [selection_function]')
    print()
    print("-d, dataset to use")
    print("\t bf = bigfoot")
    print("\t fe = flat earth")
    print("\t cc = climate change")
    print("\t va = vaccines")
    print("\t pg = pizzagate")
    print("-f, feature set, either 'word' or 'char'")
    # print("-t, test or dev mode, if it's true, then do the prediction")
    print("-r, n-gram range for features, e.g. 1,3")
    if script_name[0] == 'f':
        print("-k, number of top features, choose the target number of features here, e.g. 1000")
        print("-s, selection function for features, either 'chi2' or 'mutual_info_classif'")
    print("-h, print this help page")

    if script_name[0] == 'b':
        print("-ep, epoch")
        print("-lr, learning rate")
    print("-h, print this help page")

    return 0

def process_args(script_name):
    args = []

    try:
        # classification
        if script_name[0] == 'c':
            optlist, _ = getopt.getopt(sys.argv[1:], "hd:e:t:m:f:r:y:v:o:")
        # feautre selectio
        elif script_name[0] == 'f':
            optlist, _ = getopt.getopt(sys.argv[1:], "hd:e:t:m:f:r:k:s:y:o:")
        # bert
        elif script_name[0] == 'b':
                optlist, _ = getopt.getopt(sys.argv[1:], "hd:e:m:p:l:b:o:f:")

        for arg, val in optlist:
            if arg == "-h":
                usage(script_name)
            elif arg == "-d":
                dataset = glob_dict.get(val)
            elif arg == "-e":
                eval = glob_dict.get(val)
            # elif arg == "-t":
            #     pred = val
            elif arg == "-m":
                mode = val
                if mode == "merge":
                    ct_lsts.remove(glob_dict_rev[eval])
                    dataset = '_'.join(ct_lsts)
            elif arg == "-r":
                tmp = val.split(",")
                low = int(tmp[0])
                upp = int(tmp[1])
            elif arg == "-f":
                if val == 'char':
                    feat = val
                else:
                    eval = eval+'.'+val
                    dataset = dataset+'.'+val
                    feat = 'word'
            elif arg == "-k":
                num_feat = int(val)
            elif arg == "-s":
                func = val
            elif arg == "-o":
                outpath = val

            # bert args, epoc, learning rate, batch
            elif arg == "-p":
                p = int(val)
            elif arg == "-l":
                l = float(val)
            elif arg == "-b":
                batch = int(val)


    except Exception as e:
        print(e)
        usage(script_name)
        exit(-1)

    if script_name[0] == 'c':
        return dataset, eval, mode, feat, low, upp, outpath
    elif script_name[0] == 'b':
        return dataset, eval, mode, p, l, batch, outpath
    else:
        return dataset, eval, mode, feat, low, upp, num_feat, func, outpath



def main():
    parser = argparse.ArgumentParser(description="ct parser")

    # Add arguments from batch script
    parser.add_argument('-e', '--te', type=str, required=True, help='Testing set')
    parser.add_argument('-m', '--mode', type=str, required=True, help='Mode (merge, ??)')
    parser.add_argument('-p', '--epochs', type=int, required=True, help='Epochs')
    parser.add_argument('-l', '--lr', type=str, required=True, help='Learning rate')
    parser.add_argument('-b', '--batch', type=int, required=True, help='Batch size')
    parser.add_argument('-o', '--path', type=str, required=True, help='Output path')
    parser.add_argument('-f', '--feature', type=str, required=True, help='Feature set')

    args = parser.parse_args()

    seed, seed_eval, mode, ep, lr, batch, outpath = process_args(sys.argv[0])

    if len(sys.argv) < 10:
      print (len(sys.argv))
      usage(sys.argv[0])
      exit(1)

    seed, seed_eval, mode, ep, lr, batch, outpath = process_args(sys.argv[0])

    print (seed)
    print (seed_eval)


    if mode == 'merge': # test on seed, train on a list without seed
        tr, te, val = read_data_merge(seed,seed_eval)
    else:
        tr, te, val  = read_data(seed,seed_eval)

    tr['label'] = tr['label'].replace({'mainstream':0, 'conspiracy':1})
    te['label'] = te['label'].replace({'mainstream':0, 'conspiracy':1})
    val['label'] = val['label'].replace({'mainstream':0, 'conspiracy':1})

    tr_dataset = Dataset.from_pandas(tr)
    val_dataset = Dataset.from_pandas(val)
    te_dataset = Dataset.from_pandas(te)

    train_tokenized = tr_dataset.map(preprocess_function)
    val_tokenized = val_dataset.map(preprocess_function)
    test_tokenized = te_dataset.map(preprocess_function)

#    print(train_tokenized)
#    print(val_tokenized)
#    print(test_tokenized)
#    print()

    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

    training_args = TrainingArguments(
        output_dir='./',
        learning_rate=lr,
        per_device_train_batch_size=batch,
        per_device_eval_batch_size=1,
        num_train_epochs=ep,
        weight_decay=0.01,
        save_strategy="epoch",
        label_names=["mainstream", "conspiracy"],
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_tokenized,
        eval_dataset=val_tokenized,
        #tokenizer=tokenizer,
        compute_metrics=compute_metrics,
        data_collator=data_collator,
    )

    trainer.train()
    trainer.evaluate()

    # Eval on test set
    predictions = trainer.predict(test_tokenized)

    preds = np.argmax(predictions.predictions[1], axis=-1)

    # dataset eval
    out_res = "lizzy_results_here.csv"
    #out_res = outpath+'res_tr_'+seed+'_te_'+seed_eval+'_epochs_'+str(ep)+'_time_'+str(time.time())+'lizzy'+'.csv'

    transform_labels = ['mainstream' if x == 0 else x for x in preds]
    transform_labels = ['conspiracy' if x == 1 else x for x in transform_labels]

    te['label'] = te['label'].replace({0:'mainstream', 1:'conspiracy'})

    print(transform_labels)
    print()
    print(te['label'])

    report = classification_report(te['label'], transform_labels, digits=4, output_dict= True)
    print (report)

    df = pd.DataFrame(report).transpose()

    df.to_csv(out_res)

    # Logic of batch script
    cts = ["bf", "fe", "cc", "va", "pg"]
    tr = "tmp"

    for te in cts:
        subprocess.run([
            "python", sys.argv[0],
            "-e", te,
            "-m", mode,
            "-p", str(ep),
            "-l", lr,
            "-b", str(batch),
            "-o", outpath,
            "-f", args.feature
        ])